{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model import GoogLeNet,Studentmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0 device.\n",
      "using 3325 images for training, 364 images for validation.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using {} device.\".format(device))\n",
    "#将图像随机裁剪为224X224大小\n",
    "#以0.5的概率水平翻转\n",
    "#将RGB三个通道值标准化为[-1,1]区间\n",
    "data_transform = {\n",
    "    \"train\": transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),\n",
    "    \"val\": transforms.Compose([transforms.Resize((224, 224)),###图像大小为224X224\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])}\n",
    "\n",
    "data_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))  #\n",
    "image_path = os.path.join(data_root, \"Googlenet_flower/data_set\", \"flower_data\")  \n",
    "assert os.path.exists(image_path), \"{} path does not exist.\".format(image_path)\n",
    "train_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"train\"),\n",
    "                                     transform=data_transform[\"train\"])\n",
    "train_num = len(train_dataset)\n",
    "\n",
    "#获取类别名，并以daisy:0, dandelion:1, roses:2, sunflower:3, tulips:4的形式写入到json文件中\n",
    "flower_list = train_dataset.class_to_idx\n",
    "cla_dict = dict((val, key) for key, val in flower_list.items())\n",
    "\n",
    "json_str = json.dumps(cla_dict, indent=4)\n",
    "with open('class_indices.json', 'w') as json_file:\n",
    "    json_file.write(json_str)\n",
    "#每次训练32个样本\n",
    "batch_size = 32\n",
    "# nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  \n",
    "# print('Using {} dataloader workers every process'.format(nw))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size, shuffle=True,\n",
    "                                           )#每个epoch开始时，对数据重新排序\n",
    "\n",
    "validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"val\"),\n",
    "                                        transform=data_transform[\"val\"])\n",
    "val_num = len(validate_dataset)\n",
    "validate_loader = torch.utils.data.DataLoader(validate_dataset,\n",
    "                                              batch_size=batch_size, shuffle=False,\n",
    "                                              )\n",
    "\n",
    "print(\"using {} images for training, {} images for validation.\".format(train_num,\n",
    "                                                                 val_num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_teacher(loss_logits_wt=1,loss_aux_logits2_wt=0.3,loss_aux_logits1_wt=0.3):\n",
    "    #需要两个辅助分类器  初始化权重\n",
    "    model = GoogLeNet(num_classes=5, aux_logits=True, init_weights=True)\n",
    "    model.to(device)\n",
    "    #损失函数CrossEntropyLoss\n",
    "    #优化器Adm，学习率0.0003\n",
    "    #30个epoch\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
    "    epochs = 30\n",
    "    best_acc = 0.0\n",
    "    save_path = './googleNet.pth'##保存模型参数位置\n",
    "    train_steps = len(train_loader)\n",
    "    for epoch in range(epochs):\n",
    "        #训练 self.training=True\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
    "        for step, data in enumerate(train_bar):\n",
    "            images, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            logits, aux_logits2, aux_logits1 = net(images.to(device))\n",
    "            loss0 = loss_function(logits, labels.to(device))\n",
    "            loss1 = loss_function(aux_logits1, labels.to(device))\n",
    "            loss2 = loss_function(aux_logits2, labels.to(device))\n",
    "            loss = loss0*loss_logits_wt + loss1 *loss_aux_logits1_wt + loss2 * loss_aux_logits2_wt#总loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,\n",
    "                                                                     epochs,)\n",
    "        #测试  self.training=False 不再使用辅助分类器，只有一个输出                                                          loss)\n",
    "        model.eval()\n",
    "        acc = 0.0  \n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(validate_loader, file=sys.stdout)\n",
    "            for val_data in val_bar:\n",
    "                val_images, val_labels = val_data\n",
    "                outputs = model(val_images.to(device))  \n",
    "                predict_y = torch.max(outputs, dim=1)[1]\n",
    "                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "        val_accurate = acc / val_num#计算正确率\n",
    "        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %\n",
    "              (epoch + 1, running_loss / train_steps, val_accurate))\n",
    "        if val_accurate > best_acc:\n",
    "            best_acc = val_accurate\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "\n",
    "    print('Teacher model training completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dk(temp=5,hard_loss_wt=0.55,soft_loss_wt=0.45,loss_logits_wt=1,loss_aux_logits2_wt=0.3,loss_aux_logits1_wt=0.3):\n",
    "    teacher_model = GoogLeNet(num_classes=5, aux_logits=True).to(device)\n",
    "    weights_path = \"./googleNet.pth\"  ##训练好的模型参数保存位置\n",
    "    ####导入训练好的教师模型\n",
    "    assert os.path.exists(weights_path), \"file: '{}' dose not exist.\".format(weights_path)\n",
    "    teacher_model.load_state_dict(torch.load(weights_path, map_location=device),\n",
    "                          strict=False)\n",
    "\n",
    "    student_model=Studentmodel().to(device)\n",
    "    #hardloss采用交叉熵CrossEntropyLoss，softloss采用相对熵KL散度KLDivLoss，二者作用原理相似\n",
    "    #优化器Adm，学习率0.0001\n",
    "    #30个epoch\n",
    "    student_loss_fn = nn.CrossEntropyLoss()\n",
    "    divergence_loss_fn = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "    optimizer = torch.optim.Adam(student_model.parameters(), lr=1e-4)\n",
    "\n",
    "    teacher_model.train()#teacher_model不需要训练，由于要用到辅助分类器输出结果，此句仅为了将self.training置为true\n",
    "    student_model.train()\n",
    "\n",
    "    epochs = 30\n",
    "    best_acc = 0.0\n",
    "    save_path = './googleDKNet.pth'##保存模型参数位置\n",
    "    train_steps = len(train_loader)\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
    "        for step, data in enumerate(train_bar):\n",
    "            images, labels = data\n",
    "            images=images.to(device)\n",
    "            labels=labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                teacher_preds,teacher_preds_aux2,teacher_preds_aux1 = teacher_model(images)\n",
    "\n",
    "            student_preds=student_model(images)\n",
    "            student_loss=student_loss_fn(student_preds,labels)\n",
    "\n",
    "            ##蒸馏温度=5  学生网络与教师网络的loss等于与教师网络三个输出（两个辅助分类器）的loss加权和\n",
    "            dist_loss0 = divergence_loss_fn(F.softmax(student_preds / temp, dim=1),\n",
    "                                                    F.softmax(teacher_preds / temp, dim=1))\n",
    "            dist_loss1 = divergence_loss_fn(F.softmax(student_preds / temp, dim=1),\n",
    "                                                    F.softmax(teacher_preds_aux1 / temp, dim=1))\n",
    "            dist_loss2 = divergence_loss_fn(F.softmax(student_preds / temp, dim=1),\n",
    "                                                    F.softmax(teacher_preds_aux2 / temp, dim=1))\n",
    "\n",
    "            distillation_loss=loss_logits_wt*dist_loss0+loss_aux_logits1_wt*dist_loss1+loss_aux_logits2_wt*dist_loss2\n",
    "            \n",
    "            total_loss=student_loss*hard_loss_wt+distillation_loss*soft_loss_wt\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += total_loss.item()\n",
    "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,\n",
    "                                                                     epochs,\n",
    "                                                                     total_loss)\n",
    "        student_model.eval()\n",
    "        acc_num = 0.0  \n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(validate_loader, file=sys.stdout)\n",
    "            for val_data in val_bar:\n",
    "                val_images, val_labels = val_data\n",
    "                outputs = student_model(val_images.to(device))  \n",
    "                predict_y = torch.max(outputs, dim=1)[1]\n",
    "                acc_num += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "\n",
    "        val_accurate = acc_num / val_num\n",
    "        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %\n",
    "              (epoch + 1, running_loss / train_steps, val_accurate))\n",
    "\n",
    "        if val_accurate > best_acc:\n",
    "            best_acc = val_accurate\n",
    "            torch.save(student_model.state_dict(), save_path)\n",
    "\n",
    "    print('DK model training completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_student():\n",
    "    student_model = Studentmodel().to(device)\n",
    "    #损失函数CrossEntropyLoss\n",
    "    #优化器Adm，学习率0.0001\n",
    "    #30个epoch\n",
    "    student_loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(student_model.parameters(), lr=1e-4)\n",
    "    student_model.train()\n",
    "\n",
    "    epochs = 30\n",
    "    best_acc = 0.0\n",
    "    save_path = './studentNet.pth'  ##保存模型参数位置\n",
    "    train_steps = len(train_loader)\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
    "        for step, data in enumerate(train_bar):\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            student_preds = student_model(images)\n",
    "            loss = student_loss_fn(student_preds, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,\n",
    "                                                                     epochs,\n",
    "                                                                     loss)\n",
    "        student_model.eval()\n",
    "        acc = 0.0  \n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(validate_loader, file=sys.stdout)\n",
    "            for val_data in val_bar:\n",
    "                val_images, val_labels = val_data\n",
    "                outputs = student_model(val_images.to(device))\n",
    "                predict_y = torch.max(outputs, dim=1)[1]\n",
    "                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "\n",
    "        val_accurate = acc / val_num\n",
    "        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %\n",
    "              (epoch + 1, running_loss / train_steps, val_accurate))\n",
    "\n",
    "        if val_accurate > best_acc:\n",
    "            best_acc = val_accurate\n",
    "            torch.save(student_model.state_dict(), save_path)\n",
    "\n",
    "    print('Student model training completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_teacher()\n",
    "    train_dk()\n",
    "    train_student()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch-1.0.0",
   "language": "python",
   "name": "pytorch-1.0.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
